{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "210c114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "SUPPORTED_IMAGE_FORMATS = [\".bmp\", \".jpg\", \".jpeg\", \".png\"]\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, dataset_path: Path, processed_path: Path, image_size: Tuple[int, int], seed: int = 42):\n",
    "        self.dataset_path = Path(dataset_path)\n",
    "        self.processed_path = Path(processed_path)\n",
    "        self.image_size = image_size\n",
    "        self.seed = seed\n",
    "        random.seed(seed)\n",
    "\n",
    "    def _load_image_paths_and_labels(self) -> List[Tuple[Path, str]]:\n",
    "        \"\"\"Finds all supported image files and extracts labels from parent folders.\"\"\"\n",
    "        logger.info(f\"Loading data from {self.dataset_path}\")\n",
    "        image_paths = []\n",
    "        for class_dir in self.dataset_path.iterdir():\n",
    "            if class_dir.is_dir():\n",
    "                label = class_dir.name.lower()\n",
    "                for ext in SUPPORTED_IMAGE_FORMATS:\n",
    "                    image_paths.extend([(p, label) for p in class_dir.rglob(f\"*{ext}\")])\n",
    "        logger.info(f\"Found {len(image_paths)} images\")\n",
    "        return image_paths\n",
    "\n",
    "    def _split_dataset(\n",
    "        self,\n",
    "        data: List[Tuple[Path, str]],\n",
    "        val_split: float,\n",
    "        test_split: float\n",
    "    ) -> Tuple[List, List, List]:\n",
    "        \"\"\"Splits data into train, validation, and test sets.\"\"\"\n",
    "        if len(data) == 0:\n",
    "            raise ValueError(\"No images found to split. Please check the dataset path and format.\")\n",
    "\n",
    "        train_data, test_data = train_test_split(data, test_size=test_split, random_state=self.seed, stratify=[label for _, label in data])\n",
    "        train_data, val_data = train_test_split(train_data, test_size=val_split / (1.0 - test_split), random_state=self.seed, stratify=[label for _, label in train_data])\n",
    "        return train_data, val_data, test_data\n",
    "\n",
    "    def _copy_data_to_folder(self, data: List[Tuple[Path, str]], target_dir: Path):\n",
    "        for img_path, label in data:\n",
    "            label_dir = target_dir / label\n",
    "            label_dir.mkdir(parents=True, exist_ok=True)\n",
    "            dest_path = label_dir / img_path.name\n",
    "            shutil.copy2(img_path, dest_path)\n",
    "\n",
    "    def prepare_and_split_data(\n",
    "        self,\n",
    "        val_split: float = 0.2,\n",
    "        test_split: float = 0.1,\n",
    "        save_stats: bool = True\n",
    "    ):\n",
    "        \"\"\"Loads, splits and copies data into processed/train|val|test folders.\"\"\"\n",
    "        all_data = self._load_image_paths_and_labels()\n",
    "        train_data, val_data, test_data = self._split_dataset(all_data, val_split, test_split)\n",
    "\n",
    "        split_dirs = {\n",
    "            \"train\": self.processed_path / \"train\",\n",
    "            \"validation\": self.processed_path / \"validation\",\n",
    "            \"test\": self.processed_path / \"test\"\n",
    "        }\n",
    "\n",
    "        # Clean existing processed folders if any\n",
    "        if self.processed_path.exists():\n",
    "            logger.info(f\"Cleaning up old processed directory: {self.processed_path}\")\n",
    "            shutil.rmtree(self.processed_path)\n",
    "\n",
    "        for split_name, split_data in zip(split_dirs.keys(), [train_data, val_data, test_data]):\n",
    "            logger.info(f\"Copying {split_name} data with {len(split_data)} samples...\")\n",
    "            self._copy_data_to_folder(split_data, split_dirs[split_name])\n",
    "\n",
    "        logger.info(f\"Data organization complete. Total: {len(all_data)} images\")\n",
    "\n",
    "        # Optionally, save stats\n",
    "        if save_stats:\n",
    "            stats_path = self.processed_path / \"data_stats.json\"\n",
    "            import json\n",
    "            stats = {\n",
    "                \"total\": len(all_data),\n",
    "                \"train\": len(train_data),\n",
    "                \"validation\": len(val_data),\n",
    "                \"test\": len(test_data),\n",
    "                \"classes\": sorted({label for _, label in all_data})\n",
    "            }\n",
    "            stats_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            with open(stats_path, \"w\") as f:\n",
    "                json.dump(stats, f, indent=4)\n",
    "            logger.info(f\"Statistics saved to {stats_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
